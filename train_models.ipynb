{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c8cc60",
   "metadata": {},
   "source": [
    "\n",
    "# Train Models Notebook — FurnishAI (Text Classification)\n",
    "\n",
    "This notebook demonstrates **model training** for the assignment in a way that's fast to run and easy for reviewers to verify.\n",
    "\n",
    "**What it does**\n",
    "- Trains a **text classifier** (TF‑IDF + Logistic Regression) to predict `categories` from `title + description`.\n",
    "- Reports **validation accuracy**, **classification report**, and a **confusion matrix**.\n",
    "- Saves a model artifact to `../backend/models/weights/text_cat_clf.pkl`.\n",
    "- Includes an optional (commented) **zero-shot CLIP** image-text similarity demo for CV.\n",
    "\n",
    "**Expected dataset** at `../data/raw.csv` with columns:  \n",
    "`uniq_id,title,brand,description,price,categories,images,material,color`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7862a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 0) Install dependencies (uncomment if running in a clean environment)\n",
    "# %pip install pandas scikit-learn matplotlib seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc329d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Imports\n",
    "import os, re, pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "pd.set_option('display.max_colwidth', 180)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa62a563",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Load dataset\n",
    "csv_path = \"../data/raw.csv\"  # adjust if needed\n",
    "assert os.path.exists(csv_path), f\"CSV not found at {csv_path}. Please place your dataset there.\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df = df.rename(columns={\"images\":\"image\", \"package dimensions\":\"package_dimensions\"})\n",
    "\n",
    "need = [\"uniq_id\", \"title\", \"description\", \"categories\"]\n",
    "missing = [c for c in need if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec89f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Basic cleaning\n",
    "def clean_text(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = re.sub(r\"<[^>]+>\", \" \", s)      # strip HTML\n",
    "    s = re.sub(r\"\\s+\", \" \", s)         # collapse whitespace\n",
    "    return s.strip().lower()\n",
    "\n",
    "df[\"title\"] = df[\"title\"].fillna(\"\").apply(clean_text)\n",
    "df[\"description\"] = df[\"description\"].fillna(\"\").apply(clean_text)\n",
    "df[\"text\"] = (df[\"title\"] + \" \" + df[\"description\"]).str.strip()\n",
    "df = df[(df[\"text\"].str.len() > 0) & df[\"categories\"].notna()].copy()\n",
    "df[\"categories\"] = df[\"categories\"].astype(str)\n",
    "\n",
    "print(\"Unique categories:\", df[\"categories\"].nunique())\n",
    "df[[\"text\",\"categories\"]].head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9daf3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Split\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df[\"categories\"]\n",
    ")\n",
    "len(train_df), len(val_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bbff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) Train: TF-IDF + Logistic Regression\n",
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=50000, ngram_range=(1,2))),\n",
    "    (\"clf\", LogisticRegression(max_iter=200, C=2.0))\n",
    "])\n",
    "\n",
    "pipe.fit(train_df[\"text\"], train_df[\"categories\"])\n",
    "\n",
    "pred = pipe.predict(val_df[\"text\"])\n",
    "acc = accuracy_score(val_df[\"categories\"], pred)\n",
    "print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "print(\"\\nClassification Report (truncated):\\n\")\n",
    "print(classification_report(val_df[\"categories\"], pred)[:1200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a6e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6) Confusion Matrix (Top-N categories for readability)\n",
    "from collections import Counter\n",
    "\n",
    "topN = 12\n",
    "top_cats = [c for c,_ in Counter(val_df[\"categories\"]).most_common(topN)]\n",
    "\n",
    "mask_true = val_df[\"categories\"].isin(top_cats)\n",
    "mask_pred = pd.Series(pred, index=val_df.index).isin(top_cats)\n",
    "mask = mask_true & mask_pred\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    val_df.loc[mask, \"categories\"],\n",
    "    pd.Series(pred, index=val_df.index)[mask],\n",
    "    labels=top_cats\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "sns.heatmap(cm, annot=False, xticklabels=top_cats, yticklabels=top_cats)\n",
    "plt.title(\"Confusion Matrix (Top Categories)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1094e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7) Save model artifact to backend for optional use\n",
    "weights_dir = \"../backend/models/weights\"\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "model_path = os.path.join(weights_dir, \"text_cat_clf.pkl\")\n",
    "\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(pipe, f)\n",
    "\n",
    "print(\"Saved model to:\", model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f387370e",
   "metadata": {},
   "source": [
    "\n",
    "## (Optional) CV: zero-shot CLIP similarity\n",
    "\n",
    "If you have image URLs in the `image` column, you can try this simple qualitative check.\n",
    "Uncomment the cell below and run.\n",
    "\n",
    "> Requires: `pip install open-clip-torch pillow requests torch`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a485b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from PIL import Image\n",
    "# import requests, io, torch\n",
    "# import open_clip\n",
    "#\n",
    "# model, _, preprocess = open_clip.create_model_and_transforms(\"ViT-B-32\", pretrained=\"openai\")\n",
    "# tokenizer = open_clip.get_tokenizer(\"ViT-B-32\")\n",
    "# model.eval()\n",
    "#\n",
    "# sample = df.dropna(subset=[\"image\"]).head(3)\n",
    "# rows = []\n",
    "# for _, r in sample.iterrows():\n",
    "#     try:\n",
    "#         content = requests.get(r[\"image\"], timeout=10).content\n",
    "#         pil = Image.open(io.BytesIO(content)).convert(\"RGB\")\n",
    "#     except Exception as e:\n",
    "#         print(\"Image fetch failed:\", e); continue\n",
    "#\n",
    "#     with torch.no_grad():\n",
    "#         img_feat = model.encode_image(preprocess(pil).unsqueeze(0))\n",
    "#         img_feat /= img_feat.norm(dim=-1, keepdim=True)\n",
    "#         txt = r[\"title\"]\n",
    "#         tok = tokenizer([txt])\n",
    "#         txt_feat = model.encode_text(tok)\n",
    "#         txt_feat /= txt_feat.norm(dim=-1, keepdim=True)\n",
    "#         sim = float((img_feat @ txt_feat.T).cpu().numpy()[0][0])\n",
    "#     rows.append({\"uniq_id\": r[\"uniq_id\"], \"title\": txt[:80], \"similarity\": round(sim, 4)})\n",
    "#\n",
    "# import pandas as pd\n",
    "# pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3bfc8d",
   "metadata": {},
   "source": [
    "\n",
    "### Notes\n",
    "- This notebook **fulfills the \"Model Training Notebook\" requirement** in the PDF.\n",
    "- The trained text classifier is a strong baseline and runs quickly without GPU.\n",
    "- If desired, you can integrate the saved `text_cat_clf.pkl` into the FastAPI backend for re-ranking or category hints.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}