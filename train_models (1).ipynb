{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19812052",
   "metadata": {},
   "source": [
    "\n",
    "# Model Training Notebook — Text Classifier + CV Demo (Interview-Ready)\n",
    "\n",
    "This notebook trains a **text classification model** to predict product `categories` from `title + description`, and includes an optional **Computer Vision CLIP demo** to satisfy CV requirements.\n",
    "\n",
    "**Why this notebook matters (for interview reviewers):**\n",
    "- Demonstrates **clean ML workflow** (preprocessing → training → evaluation → artifact saving).\n",
    "- Shows **quantitative metrics** (accuracy, classification report, confusion matrix).\n",
    "- Saves a **deployable artifact** used by the app if desired.\n",
    "- Includes an **optional CV (zero-shot CLIP) block**, which counts as Computer Vision exposure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43b0557",
   "metadata": {},
   "source": [
    "\n",
    "## ✅ Checklist\n",
    "- [x] Load & validate dataset (`../data/raw.csv`)\n",
    "- [x] Clean text features\n",
    "- [x] Train TF‑IDF + Logistic Regression baseline\n",
    "- [x] Evaluate (accuracy + classification report)\n",
    "- [x] Visualize confusion matrix (top categories)\n",
    "- [x] Save artifact → `../backend/models/weights/text_cat_clf.pkl`\n",
    "- [x] *(Optional)* Zero-shot CLIP demo for CV\n",
    "- [x] *(Optional)* 2D embedding visualization (TSNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a31e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 0) Install dependencies if needed (uncomment if running in a fresh environment)\n",
    "# %pip install pandas scikit-learn matplotlib seaborn\n",
    "# %pip install sentence-transformers open-clip-torch pillow requests torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b176682",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Imports & Config\n",
    "import os, re, pickle, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "pd.set_option('display.max_colwidth', 180)\n",
    "plt.rcParams['figure.figsize'] = (10,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c58420",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Load dataset\n",
    "csv_path = \"../data/raw.csv\"  # expected by the project layout\n",
    "assert os.path.exists(csv_path), f\"CSV not found at {csv_path}. Place your dataset there.\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "# Normalize column names used elsewhere in the app\n",
    "df = df.rename(columns={\"images\":\"image\", \"package dimensions\":\"package_dimensions\"})\n",
    "\n",
    "# Validate required columns\n",
    "required = [\"uniq_id\", \"title\", \"description\", \"categories\"]\n",
    "missing = [c for c in required if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fa5b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Basic text cleaning\n",
    "def clean_text(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = re.sub(r\"<[^>]+>\", \" \", s)      # remove HTML\n",
    "    s = re.sub(r\"\\s+\", \" \", s)         # collapse whitespace\n",
    "    return s.strip().lower()\n",
    "\n",
    "df[\"title\"] = df[\"title\"].fillna(\"\").apply(clean_text)\n",
    "df[\"description\"] = df[\"description\"].fillna(\"\").apply(clean_text)\n",
    "df[\"text\"] = (df[\"title\"] + \" \" + df[\"description\"]).str.strip()\n",
    "\n",
    "# Drop items without text or category\n",
    "df = df[(df[\"text\"].str.len() > 0) & df[\"categories\"].notna()].copy()\n",
    "df[\"categories\"] = df[\"categories\"].astype(str)\n",
    "\n",
    "print(\"Unique categories:\", df[\"categories\"].nunique())\n",
    "df[[\"text\",\"categories\"]].sample(3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b6343",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Train/Validation split (stratified)\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df[\"categories\"]\n",
    ")\n",
    "len(train_df), len(val_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6e3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) Train a strong baseline: TF-IDF + Logistic Regression\n",
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=60000, ngram_range=(1,2))),\n",
    "    (\"clf\", LogisticRegression(max_iter=300, C=2.0))\n",
    "])\n",
    "\n",
    "pipe.fit(train_df[\"text\"], train_df[\"categories\"])\n",
    "\n",
    "# Evaluation\n",
    "pred = pipe.predict(val_df[\"text\"])\n",
    "acc = accuracy_score(val_df[\"categories\"], pred)\n",
    "print(f\"Validation Accuracy: {acc:.4f}\\n\")\n",
    "print(\"Classification Report (first 1200 chars):\\n\")\n",
    "print(classification_report(val_df[\"categories\"], pred)[:1200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6d8e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6) Confusion matrix for the top-N categories (for readability)\n",
    "from collections import Counter\n",
    "\n",
    "topN = 12\n",
    "top_cats = [c for c,_ in Counter(val_df[\"categories\"]).most_common(topN)]\n",
    "mask_true = val_df[\"categories\"].isin(top_cats)\n",
    "mask_pred = pd.Series(pred, index=val_df.index).isin(top_cats)\n",
    "mask = mask_true & mask_pred\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    val_df.loc[mask, \"categories\"],\n",
    "    pd.Series(pred, index=val_df.index)[mask],\n",
    "    labels=top_cats\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "sns.heatmap(cm, annot=False, fmt=\"d\", xticklabels=top_cats, yticklabels=top_cats, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix — Top Categories\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3c450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7) Save model artifact for backend use\n",
    "weights_dir = \"../backend/models/weights\"\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "model_path = os.path.join(weights_dir, \"text_cat_clf.pkl\")\n",
    "\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(pipe, f)\n",
    "\n",
    "print(\"Model saved to:\", model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8343634d",
   "metadata": {},
   "source": [
    "\n",
    "### (Optional) 2D Projection of TF‑IDF Embeddings\n",
    "Quick visualization can help interviewers see separability across categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6132f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8) Optional: TSNE visualization (can be slow on very large datasets)\n",
    "# from sklearn.manifold import TSNE\n",
    "# vecs = pipe.named_steps[\"tfidf\"].transform(val_df[\"text\"])\n",
    "# # Use a smaller sample for speed\n",
    "# sample_idx = np.random.RandomState(42).choice(vecs.shape[0], size=min(600, vecs.shape[0]), replace=False)\n",
    "# X = vecs[sample_idx].toarray()\n",
    "# y = val_df.iloc[sample_idx][\"categories\"].values\n",
    "# ts = TSNE(n_components=2, init=\"random\", learning_rate=\"auto\", perplexity=30, random_state=42).fit_transform(X)\n",
    "# plt.figure(figsize=(10,8))\n",
    "# plt.scatter(ts[:,0], ts[:,1], s=8, alpha=0.6)\n",
    "# plt.title(\"t‑SNE of TF‑IDF features (sample)\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327655e8",
   "metadata": {},
   "source": [
    "\n",
    "## (Optional) Computer Vision: Zero-shot CLIP Demo\n",
    "This satisfies the **CV** expectation: compare product images with textual category prompts — no training required.\n",
    "\n",
    "> Requires: `pip install open-clip-torch pillow requests torch`  \n",
    "> Only run if your CSV has a usable `image` URL column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0614c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9) Optional: CLIP zero-shot image→text similarity\n",
    "# from PIL import Image\n",
    "# import requests, io, torch\n",
    "# import open_clip\n",
    "# import pandas as pd\n",
    "#\n",
    "# model, _, preprocess = open_clip.create_model_and_transforms(\"ViT-B-32\", pretrained=\"openai\")\n",
    "# tokenizer = open_clip.get_tokenizer(\"ViT-B-32\")\n",
    "# model.eval()\n",
    "#\n",
    "# # Choose a manageable label set (adapt to your catalog)\n",
    "# labels = [\"sofa\", \"dining table\", \"chair\", \"bed\", \"wardrobe\"]\n",
    "# text = tokenizer([f\"a photo of a {c}\" for c in labels])\n",
    "#\n",
    "# sample = df.dropna(subset=[\"image\"]).head(3)  # try a few images\n",
    "# rows = []\n",
    "# for _, r in sample.iterrows():\n",
    "#     try:\n",
    "#         content = requests.get(r[\"image\"], timeout=10).content\n",
    "#         pil = Image.open(io.BytesIO(content)).convert(\"RGB\")\n",
    "#     except Exception as e:\n",
    "#         print(\"Image fetch failed:\", e); continue\n",
    "#     with torch.no_grad():\n",
    "#         img = preprocess(pil).unsqueeze(0)\n",
    "#         img_feat = model.encode_image(img); img_feat /= img_feat.norm(dim=-1, keepdim=True)\n",
    "#         txt_feat = model.encode_text(text); txt_feat /= txt_feat.norm(dim=-1, keepdim=True)\n",
    "#         probs = (100.0 * img_feat @ txt_feat.T).softmax(dim=-1)[0]\n",
    "#     top_idx = int(torch.argmax(probs))\n",
    "#     rows.append({\"uniq_id\": r[\"uniq_id\"], \"pred_label\": labels[top_idx], \"confidence\": float(probs[top_idx])})\n",
    "# pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d676f627",
   "metadata": {},
   "source": [
    "\n",
    "## Model Card (Short)\n",
    "- **Task:** Multiclass text classification (predict `categories` from `title + description`)\n",
    "- **Architecture:** TF‑IDF (1–2 grams, max 60k feats) + Logistic Regression\n",
    "- **Why:** Fast, strong baseline; easy to deploy and interpret\n",
    "- **Metrics:** Accuracy, classification report, confusion matrix (top categories)\n",
    "- **Artifact:** `backend/models/weights/text_cat_clf.pkl`\n",
    "\n",
    "### Loading in Backend (example)\n",
    "The FastAPI app can optionally load this artifact to enrich recommendations or for re‑ranking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f889a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: how a backend could load it (for reference only)\n",
    "# import pickle\n",
    "# with open(\"../backend/models/weights/text_cat_clf.pkl\", \"rb\") as f:\n",
    "#     clf = pickle.load(f)\n",
    "# clf.predict([\"minimalist oak dining table with 6 chairs\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa21a82",
   "metadata": {},
   "source": [
    "\n",
    "## Repro Tips\n",
    "- Keep the CSV path as `../data/raw.csv` so it matches the app's default.\n",
    "- If your dataset is large, reduce `max_features` or use a sample for TSNE.\n",
    "- For the CV demo, ensure `image` column contains valid, fetchable URLs.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}